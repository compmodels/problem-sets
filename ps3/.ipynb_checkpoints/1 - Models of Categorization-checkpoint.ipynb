{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-warning\"><b>N.B.: </b> This notebook has three sections that together make up half the problem set. Budget your time accordingly!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The inhabitants of the planet Boton love pushing buttons. There are many kinds of buttons on Boton: red buttons, blue buttons, big buttons, small buttons. In fact, there are four dimensions along which buttons vary:\n",
    "\n",
    "![](images/concepts.png)\n",
    "\n",
    "Not all buttons do the same thing when pushed. Some are harmless, but others are dangerous and self-destruct. As young Botonans grow up, they are taught which buttons are safe to push and which are unsafe. Unfortunately, there are no hard-and-fast rules about which buttons are safe or unsafe, so young Botonans must develop a scheme for categorizing the buttons. For example, a Botonan might observe the following:\n",
    "<a name=\"exemplars\"></a>\n",
    "\n",
    "![](images/exemplars.png)\n",
    "\n",
    "Clearly, it's not enough to say that all the blue buttons are safe because there is at least one blue button known to be unsafe. So, how do the Botonans determine which buttons are safe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Context Model: Part A (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "As a cognitive scientist, you know a few different models of categorization that have been proposed. For example, you might remember the *context model* described by Medin and Schaffer (1978). The context model is an exemplar model: the probability that a stimulus is assigned to a category is based on its similarity to all the exemplars in that category.\n",
    "\n",
    "To use the context model, we represent each stimulus (button) as a vector. For example, we can represent a big square blue textured button as $\\mathbf{x}=[1, 0, 1, 1]$. Similarly, we can represent the stimulus which is small red cicular textured button as $\\mathbf{x}=[0, 1, 0, 1]$. Given this representation, we can now define a similarity function.\n",
    "\n",
    "> <a name=\"eq:similarity\"></a>The similarity $\\mathbb{S}$ of one stimulus $\\mathbf{x}$ to another stimulus $\\mathbf{y}$ is given by the following set of equations:\n",
    ">\n",
    "> $$\n",
    "\\begin{align*}\n",
    "\\mathbb{S}(\\mathbf{x}, \\mathbf{y}) &= \\prod_{i = 1}^m s(x_i, y_i)=s(x_1, y_1)\\cdot{}s(x_2, y_2)\\cdot{}\\ldots{}\\cdot{}s(x_m, y_m)\\\\\n",
    "s(x_i, y_i) &= \\left\\{\n",
    "\\begin{array}{rl} 1 & \\text{if } x_{i} = y_{i} \\\\\n",
    "   \\theta & \\text{if } x_{i} \\neq y_{i}\\end{array}\\right.\n",
    "   \\end{align*}\n",
    "$$\n",
    ">\n",
    "> where $\\theta$ is a constant.\n",
    "\n",
    "(Remember that $\\Pi$ is like $\\Sigma$, except that you multiply the terms together instead of summing them. For example, $\\prod_{k=1}^5{k} = 1 \\cdot 2 \\cdot 3 \\cdot 4 \\cdot 5 = 5! = 120$. Or, if $\\mathbf{v}=[4,1,2]$ then, $\\prod_{i=1}^3{v_i}=4 \\cdot 1 \\cdot 2 = 8$.)\n",
    "\n",
    "So, if one stimulus is $\\mathbf{x}=[1, 0, 1, 1]$ and the other is $\\mathbf{y}=[0, 1, 1, 0]$, then we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{S}(\\mathbf{x}, \\mathbf{y}) &= \\prod_{i=1}^4 s(x_i, y_i) \\\\\n",
    "&= s(x_1, y_1) \\cdot{} s(x_2, y_2) \\cdot{} s(x_3, y_3) \\cdot{} s(x_4, y_4) \\\\\n",
    "&= \\theta \\cdot{} \\theta \\cdot{} 1 \\cdot{} \\theta \\\\\n",
    "&= \\theta^3\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Complete the function `calculate_similarity` to calculate the similarity $\\mathbb{S}(\\mathbf{x}, \\mathbf{y})$ between two stimuli (as defined in the [similarity equation](#eq:similarity)).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "42b5f9650074de12fe860e0cf5a0e87c",
     "grade": false,
     "grade_id": "calculate_similarity",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(x, y, theta=0.1):\n",
    "    \"\"\"Calculates the similarity between a stimulus x and a \n",
    "    stimulus y, where similarity is defined as:\n",
    "    \n",
    "        S(x, y) = s(x_1, y_1) * s(x_2, y_2) * ... * s(x_m, y_m)\n",
    "    \n",
    "    and:\n",
    "    \n",
    "        s(x_i, y_i) = 1 if x_i == y_i, theta otherwise\n",
    "        \n",
    "    Note: your solution can be done in one line of code, including \n",
    "    the return statement. Think about how many times you need to \n",
    "    multiply theta with itself. How can you easily compute this \n",
    "    number?\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : numpy arrays with shape (m,)\n",
    "        The stimuli to compute similarity between\n",
    "    theta : (optional) float\n",
    "        A parameter to the similarity function. When the function is\n",
    "        called without theta having been specified, it defaults to 0.1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float : the similarity between x and y\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Verify that your function works on the example we worked out above (is the answer it returns equivalent to $\\theta^3$?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "x = np.array([1, 0, 1, 1])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "print(\"S(x, y) = {}\".format(calculate_similarity(x, y)))\n",
    "print(\"S(x, y, theta=0.3) = {}\".format(calculate_similarity(x, y, theta=0.3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6d350e910e2482ccc756493ce912e9c8",
     "grade": true,
     "grade_id": "test_calculate_similarity",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that calculate_similarity works correctly.\"\"\"\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "x = np.ones(8)\n",
    "y = np.zeros(8)\n",
    "assert_allclose(calculate_similarity(x, x), 1.0)\n",
    "assert_allclose(calculate_similarity(x, y), 1e-08)\n",
    "assert_allclose(calculate_similarity(x, y, theta=2.0), 256.0)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.47), 0.002381128666176099)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1), 1)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1.2), 4.2998169599999985)\n",
    "\n",
    "x = np.array([1, 0, 1, 0])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "assert_allclose(calculate_similarity(x, y), 0.01)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.2), 0.04)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.3), 0.09)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.47), 0.22089999999999999)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1), 1)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1.2), 1.44)\n",
    "\n",
    "x = np.array([0, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n",
    "y = np.array([1, 1, 1, 0, 0, 1, 0, 1, 1, 0])\n",
    "assert_allclose(calculate_similarity(x, y), 1e-6)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.2), 6.4e-5)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.3), 0.0007289999999999998)\n",
    "assert_allclose(calculate_similarity(x, y, theta=0.47), 0.010779215328999996)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1), 1)\n",
    "assert_allclose(calculate_similarity(x, y, theta=1.2), 2.9859839999999993)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Context Model: Part B (1.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now that we have defined the similarity between two stimuli, we can take a look at the equation for the context model. In the definition below, you can think of category $A$ as being the *safe buttons*, and category $B$ as being the *unsafe buttons*.\n",
    "\n",
    "> <a name=\"eq:context-model\"></a>The context model, which gives the probability that a novel stimulus $\\mathbf{x}$ belongs to category $A$ (as opposed to category $B$) is given by:\n",
    ">\n",
    "> $$\n",
    "P(A|\\mathbf{x}) = \\frac{\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})}{\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})+ \\sum_{\\mathbf{b} \\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})}\n",
    "$$\n",
    ">\n",
    "> where $\\sum_{\\mathbf{a} \\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})$ is the sum over the similarity of $\\mathbf{x}$ to all exemplars $\\mathbf{a}$ in category $A$, and $\\sum_{\\mathbf{b} \\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})$ is the sum over the similarity of $\\mathbf{x}$ to all exemplars $\\mathbf{b}$ in category $B$.\n",
    "\n",
    "Note that because $P(A|\\mathbf{x})$ is a probability, we can easily compute from it the probability that $\\mathbf{x}$ belongs to category $B$. The stimulus *must* belong to one of the two categories, thus $P(B|\\mathbf{x})=1-P(A|\\mathbf{x})$.\n",
    "\n",
    "Let's work through an example of this. Suppose there is one test stimulus $\\mathbf{x} = [1, 0, 1]$, and four exemplars: $\\mathbf{a}_1=[0, 0, 0]$ and $\\mathbf{a}_2=[0, 0, 1]$ (which have category labels of $A$) and $\\mathbf{b}_1=[1, 1, 1]$ and $\\mathbf{b}_2=[0, 1, 1]$ (which have category labels of $B$). Then:\n",
    "\n",
    "$$\n",
    "P(A|\\mathbf{x}) = \\frac{\\sum_{\\mathbf{a}\\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a})}{\\sum_{\\mathbf{a}\\in A} \\mathbb{S}(\\mathbf{x}, \\mathbf{a}) + \\sum_{\\mathbf{b}\\in B} \\mathbb{S}(\\mathbf{x}, \\mathbf{b})}=\\frac{\\mathbb{S}(\\mathbf{x}, \\mathbf{a}_1) + \\mathbb{S}(\\mathbf{x}, \\mathbf{a}_2)}{\\mathbb{S}(\\mathbf{x}, \\mathbf{a}_1) + \\mathbb{S}(\\mathbf{x}, \\mathbf{a}_2) + \\mathbb{S}(\\mathbf{x}, \\mathbf{b}_1) + \\mathbb{S}(\\mathbf{x}, \\mathbf{b}_2)}\n",
    "$$\n",
    "\n",
    "where $\\mathbb{S}$ is the [similarity function](#eq:similarity) that we defined above and implemented in `calculate_similarity`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Write code that uses your function `calculate_similarity` to implement a version of the context model (i.e., computes the [context model equation](#eq:context-model)). Complete the function `context_model` with your solution.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a09f86d77a6a5e737de7d87fab61fa9b",
     "grade": false,
     "grade_id": "context_model",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def context_model(test_stimuli, exemplars, exemplar_categories, theta=0.1):\n",
    "    \"\"\"Computes the probability that each test stimulus belongs to \n",
    "    category A.\n",
    "    \n",
    "    Note: your solution can be done in 7 lines of code, including \n",
    "    the return statement\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stimuli : numpy array with shape (n, m)\n",
    "        n stimuli, each with m features, to be classified (i.e. \n",
    "        compute P(A|x) for each x)\n",
    "    exemplars : numpy array with shape (k, m)\n",
    "        k exemplars, each with m features\n",
    "    exemplar_categories : numpy string array with shape (k,)\n",
    "        Categories for the k exemplars. You can assume the values of \n",
    "        exemplar_categories will always be either be \"A\" or \"B\".\n",
    "    theta : (optional) float\n",
    "        A parameter to pass to the similarity function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (n,) such that the i^th element \n",
    "    corresponds to P(A|test_stimuli[i])\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "950efa4032f63d14935717df248b4b2c",
     "grade": true,
     "grade_id": "test_context_model",
     "locked": false,
     "points": 1.75,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that the context model is correct.\"\"\"\n",
    "\n",
    "# check that output has the correct shape and is always probabilties\n",
    "for i in range(100):\n",
    "    n, m, k = np.random.randint(2, 10, size=(3,))\n",
    "    test_stimuli = np.random.choice(np.array([1, 0]), size=(n,m))\n",
    "    test_exemplars = np.random.choice(np.array([1, 0]), size=(k,m))\n",
    "    test_exemplar_categories = np.append(np.random.choice([\"A\", \"B\"], size=(k-2,)), [\"A\", \"B\"])\n",
    "    ps = context_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "    \n",
    "    assert ps.shape == (n,)\n",
    "    assert ((ps >= 0) & (ps <= 1)).all()\n",
    "\n",
    "# check that output is exactly right for a small example\n",
    "test_stimuli = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 1]])\n",
    "test_exemplars = np.array([[1, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0]])\n",
    "test_exemplar_categories = np.array([\"B\", \"A\", \"A\", \"A\"])\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.95454545,  0.91735537,  0.17355372]))\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.2),\n",
    "    np.array([ 0.91666667,  0.86111111,  0.30555556]))\n",
    "\n",
    "# check that output is exactly right for a larger example\n",
    "test_stimuli = np.array([\n",
    "    [1, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 1]])\n",
    "test_exemplars = np.array([\n",
    "    [0, 0, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 1]])\n",
    "test_exemplar_categories = np.array(['B', 'A', 'B', 'B', 'B', 'A'])\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.97868217,  0.32465445,  0.900018  ,  0.9009009 ]))\n",
    "assert_allclose(\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.5),\n",
    "    np.array([ 0.625     ,  0.32258065,  0.53125   ,  0.57142857]))\n",
    "\n",
    "# check that it uses calculate_similarity\n",
    "old_calculate_similarity = calculate_similarity\n",
    "del calculate_similarity\n",
    "try:\n",
    "    context_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"context_model does not call the calculate_similarity function\")\n",
    "finally:\n",
    "    calculate_similarity = old_calculate_similarity\n",
    "    del old_calculate_similarity\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Context Model: Part C (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now that you have an implementation of the context model, let's try it out! First, let's see how well it does at categorizing the [exemplars that we already have](#exemplars):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da1ed2c45d5c5d2262574a1c357e8dd5",
     "grade": false,
     "grade_id": "exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "safe_exemplars = np.array([\n",
    "    [0, 1, 1, 0], # circle / small / blue / solid\n",
    "    [1, 0, 1, 0], # square / big   / blue / solid\n",
    "    [1, 1, 0, 0], # square / small / red  / solid\n",
    "    [1, 1, 1, 1]  # square / small / blue / textured\n",
    "])\n",
    "unsafe_exemplars = np.array([\n",
    "    [1, 1, 0, 1], # square / small / red  / textured\n",
    "    [0, 0, 0, 1], # circle / big   / red  / textured\n",
    "    [0, 1, 1, 1], # circle / small / blue / textured\n",
    "    [0, 1, 0, 0]  # circle / small / red  / solid\n",
    "])\n",
    "all_exemplars = np.vstack([safe_exemplars, unsafe_exemplars])\n",
    "exemplar_categories = np.array([\"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a250cf02b856312d738c1df018b17f99",
     "grade": false,
     "grade_id": "context_model_exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "context_model(all_exemplars, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Describe how well the context model does at categorizing the known exemplars. Does it give a higher value for $P(A|\\mathbf{x})$ for those $\\mathbf{x}$ which are actually in category $A$? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e3283cc37aa7f95508da3e2b8c3ff69e",
     "grade": true,
     "grade_id": "context_model_part_c",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Context Model: Part D (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "A young Botonan is strolling through the city, when a flash of blue and red is seen coming from an alleyway. Taking a closer look, the youngster discovers four buttons never before encountered:\n",
    "<a name=\"novel\"></a>\n",
    "\n",
    "![](images/novel.png)\n",
    "\n",
    "As a Botonan, this youngster feels a strong urge to push the buttons. However, the possibility that some of the buttons might be dangerous demands restraint. The Botonan pauses and takes a closer look.\n",
    "\n",
    "Let's see what the context model says about how likely these buttons are to be dangerous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8d38522078912c176dfccb80ddeda1e0",
     "grade": false,
     "grade_id": "novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "novel_stimuli = np.array([\n",
    "    [0, 0, 0, 0], # circle / big   / red  / solid\n",
    "    [1, 0, 0, 1], # square / big   / red  / textured\n",
    "    [1, 0, 1, 1], # square / big   / blue / textured\n",
    "    [0, 0, 1, 0]  # circle / big   / blue / solid\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ce20365830cd81be253dde86fa2a6699",
     "grade": false,
     "grade_id": "context_model_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "context_model(novel_stimuli, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">In words, what does the context model say? Which of these buttons are more likely to belong to category A (safe buttons)? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "292a19386e9054afef9ce14acaa9282f",
     "grade": true,
     "grade_id": "context_model_part_d_1",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">If the context model is an accurate model of how Botonans categorize concepts, do you think they would push any of the buttons? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5607e51996ef317ce0f0632991128cb9",
     "grade": true,
     "grade_id": "context_model_part_d_2",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Prototype Model: Part A (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "You also know of another model of categorization: the prototype model. This model is similar to the context model, but rather than comparing the new stimulus to all of the exemplars, it compares the new stimulus to the category *prototypes*. How do we know what the category prototype is? Recall from the last problem set that we can compute a prototype from a set of exemplars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Complete the following `prototype` function (it is fine if you reuse your code from the last problem set--- but make sure that it actually works as expected!).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6a00dadbf1ad9c096a79323dac1d631",
     "grade": false,
     "grade_id": "prototype",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def prototype(features):\n",
    "    \"\"\"\n",
    "    Compute the prototype features, based on the given features of\n",
    "    category members. The prototype should have a feature if half or\n",
    "    more of the category members have that feature.\n",
    "\n",
    "    Hint: you can use your implementation of `prototype` from the\n",
    "    last problem set here, though you may want to cast the array to \n",
    "    integers to match the format elsewhere (try `.astype(int)`).\n",
    "    \n",
    "    Your solution can be done in 1 line of code (including the return \n",
    "    statement).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features : numpy array with shape (n, m)\n",
    "        The first dimension corresponds to n category members, and the\n",
    "        second dimension to m features.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (m,) corresponding to the features\n",
    "    of the prototype of the category members\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3424f5ae29fa1c5e09adb4b795f127c7",
     "grade": true,
     "grade_id": "test_prototype",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test the prototype function.\"\"\"\n",
    "from nose.tools import assert_equal\n",
    "from numpy.testing import assert_array_equal\n",
    "\n",
    "# make sure they get features that are half or more\n",
    "assert_array_equal(prototype(np.array([[0, 1], [0, 0]])), np.array([0, 1]))\n",
    "\n",
    "for i in range(10):\n",
    "    # create a random array of features\n",
    "    n, m = np.random.randint(10, 100, 2)\n",
    "    features = np.random.randint(0, 2, (n, m))\n",
    "    \n",
    "    # compute the prototype\n",
    "    proto = prototype(features)\n",
    "    \n",
    "    # check the shape and type\n",
    "    assert_equal(proto.shape, (m,), \"incorrect shape for the prototype array\")\n",
    "    \n",
    "    # check that the prototype is correct\n",
    "    for j in range(m):\n",
    "        count = features[:, j].sum()\n",
    "        if count >= (n / 2) and not proto[j]:\n",
    "            raise AssertionError(\"prototype should have feature {}, but it doesn't\".format(j))\n",
    "        elif count < (n / 2) and proto[j]:\n",
    "            raise AssertionError(\"prototype should NOT have feature {}, but it does\".format(j))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<a name=\"prototypes\"></a>Check what your function returns for the \"safe button\" prototype and the \"unsafe button\" prototype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7dbae3e6a285d80a28e01efc1f40349c",
     "grade": false,
     "grade_id": "prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "safe_prototype = prototype(safe_exemplars)\n",
    "unsafe_prototype = prototype(unsafe_exemplars)\n",
    "print(\"Safe button prototype: {}\".format(safe_prototype))\n",
    "print(\"Unsafe button prototype: {}\".format(unsafe_prototype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Describe in words what the features of each prototype are (e.g., \"the safe button prototype is a [size], [color], [fill] [shape]\"). Remember that the first feature corresponds to shape, the second feature corresponds to size, the third feature corresponds to color, and the fourth feature corresponds to fill. (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ad0861b070ce222a4c99810d30984168",
     "grade": true,
     "grade_id": "prototype_part_a",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Prototype Model: Part B (1.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now that we have a way of computing prototypes from our exemplars, let's take a look at the actual prototype model.\n",
    "\n",
    "<a name=\"eq:prototype\"></a>\n",
    "> The prototype model can be described by the following equation:\n",
    ">\n",
    "> $$\n",
    "P(A|\\mathbf{x})=\\frac{\\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_A)}{\\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_A) + \\mathbb{S}(\\mathbf{x}, \\mathbf{\\mu}_B)}\n",
    "$$\n",
    ">\n",
    "> where $\\mathbb{S}$ is the [similarity function defined above](#eq:similarity), $\\mathbf{x}$ is the novel stimulus, $\\mathbf{\\mu}_A$ is the prototype of category $A$, and $\\mathbf{\\mu}_B$ is the prototype of category $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Using your `calculate_similarity` function and your `prototype` function, complete the function `prototype_model` below to implement the [prototype model equation](#eq:prototype).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4651a98b2961132f9e078f991930bded",
     "grade": false,
     "grade_id": "prototype_model",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def prototype_model(test_stimuli, exemplars, exemplar_categories, theta=0.1):\n",
    "    \"\"\"Computes the probability that each test stimulus belongs to \n",
    "    category A.\n",
    "    \n",
    "    Note: your solution can be done in 8 lines of code, including\n",
    "    the return statement.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_stimuli : numpy array with shape (n, m)\n",
    "        n stimuli, each with m features, to be classified (i.e. \n",
    "        compute P(A|x) for each x)\n",
    "    exemplars : numpy array with shape (k, m)\n",
    "        k exemplars, each with m features\n",
    "    exemplar_categories : numpy string array with shape (k,)\n",
    "        Categories for the k exemplars. You can assume the values of \n",
    "        exemplar_categories will always be either be \"A\" or \"B\".\n",
    "    theta : (optional) float\n",
    "        A parameter to pass to the similarity function. If theta is not\n",
    "        specified, it defaults to 0.1.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (n,) such that the i^th element \n",
    "    corresponds to P(A|test_stimuli[i])\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "41cf87f8d58a37b4f2aaab397f844b44",
     "grade": true,
     "grade_id": "test_prototype_model",
     "locked": false,
     "points": 1.75,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that the prototype model is correct.\"\"\"\n",
    "\n",
    "# check that output has the correct shape and is always probabilties\n",
    "for i in range(100):\n",
    "    n, m, k = np.random.randint(2, 10, size=(3,))\n",
    "    test_stimuli = np.random.choice(np.array([1, 0]), size=(n,m))\n",
    "    test_exemplars = np.random.choice(np.array([1, 0]), size=(k,m))\n",
    "    test_exemplar_categories = np.append(np.random.choice([\"A\", \"B\"], size=(k-2,)), [\"A\", \"B\"])\n",
    "    ps = prototype_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "    \n",
    "    assert ps.shape == (n,)\n",
    "    assert ((ps >= 0) & (ps <= 1)).all()\n",
    "\n",
    "# check that output is exactly right for a small example\n",
    "test_stimuli = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 1]])\n",
    "test_exemplars = np.array([[1, 1, 0], [0, 0, 1], [0, 0, 0], [1, 0, 0]])\n",
    "test_exemplar_categories = np.array([\"B\", \"A\", \"A\", \"A\"])\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.5       ,  0.5       ,  0.00990099]))\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.2),\n",
    "    np.array([ 0.5       ,  0.5       ,  0.03846154]))\n",
    "\n",
    "# check that output is exactly right for a larger example\n",
    "test_stimuli = np.array([\n",
    "    [1, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 1]])\n",
    "test_exemplars = np.array([\n",
    "    [0, 0, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [1, 0, 0, 0, 1],\n",
    "    [0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 1]])\n",
    "test_exemplar_categories = np.array(['B', 'A', 'B', 'B', 'B', 'A'])\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories),\n",
    "    np.array([ 0.999001  ,  0.09090909,  0.90909091,  0.999001  ]))\n",
    "assert_allclose(\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories, theta=0.5),\n",
    "    np.array([ 0.88888889,  0.33333333,  0.66666667,  0.88888889]))\n",
    "\n",
    "# check that it uses calculate_similarity\n",
    "old_calculate_similarity = calculate_similarity\n",
    "del calculate_similarity\n",
    "try:\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"prototype_model does not call the calculate_similarity function\")\n",
    "finally:\n",
    "    calculate_similarity = old_calculate_similarity\n",
    "    del old_calculate_similarity\n",
    "    \n",
    "# check that it uses prototype\n",
    "old_prototype = prototype\n",
    "del prototype\n",
    "try:\n",
    "    prototype_model(test_stimuli, test_exemplars, test_exemplar_categories)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"prototype_model does not call the prototype function\")\n",
    "finally:\n",
    "    prototype = old_prototype\n",
    "    del old_prototype\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Prototype Model: Part C (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Let's see how well the prototype model does at categorizing the prototypes of safe and unsafe buttons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c70dfe4b5fec0bfef36244c092da1095",
     "grade": false,
     "grade_id": "prototype_model_prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "prototypes = np.vstack([safe_prototype, unsafe_prototype])\n",
    "prototype_model(prototypes, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">How well does it do? Does it classify the safe prototype as safe, and the unsafe prototype as unsafe? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fd3d85c708ba66cfd5024894c9ee37bd",
     "grade": true,
     "grade_id": "prototype_part_c",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Prototype Model: Part D (0.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now let's see what the prototype model would say about the [unknown buttons](#novel) that our young Botonan has encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67fb759baa91c2dccbe0deec412b5de8",
     "grade": false,
     "grade_id": "prototype_model_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "prototype_model(novel_stimuli, all_exemplars, exemplar_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">What does the prototype model say? Which of these buttons are more likely to belong to category A (safe buttons)? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d66ec0870c1f6b9218cbb1761a7fede3",
     "grade": true,
     "grade_id": "prototype_part_d_1",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">What does the prototype model say? Which of these buttons are more likely to belong to category A (safe buttons)? If the prototype model is an accurate model of how Botonans categorize concepts, do you think they would push any of the buttons? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2479a3e0df31f8f0be3e894d37b488a3",
     "grade": true,
     "grade_id": "prototype_part_d_2",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Comparing Models: Part A (0.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "As we develop computational models of cognition, it is not enough to look at a single model and declare that it is good or bad. What is it good or bad in relation to? We must always *compare* our models, in order to get a better sense of how the space of models behave on a particular type of problem.\n",
    "\n",
    "We have now analyzed the context model and prototype model independently, but we have not compared them. First, let's compare how they both behave on the exemplars that have already been observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f7a04a1868c626309012331c4173a3a",
     "grade": false,
     "grade_id": "comparing_exemplars",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Context model on exemplars:    {}\".format(context_model(all_exemplars, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on exemplars:  {}\".format(prototype_model(all_exemplars, all_exemplars, exemplar_categories)))\n",
    "print(\"True exemplar categories:      {}\".format(exemplar_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Which model is more accurate at predicting the exemplar categories? (**0.25 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "01a957659a6ae6f0307be85126630216",
     "grade": true,
     "grade_id": "comparing_part_a_1",
     "locked": false,
     "points": 0.25,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Even though the models have seen these exemplars, and know their true categories, they do not predict the category labels with 100% certainty. Why is this the case? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a170ba17662980f57450ec9aec61dae8",
     "grade": true,
     "grade_id": "comparing_part_a_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "\n",
    "## Comparing Models: Part B (0.75 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now let's take a look at how well the models perform on the prototypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bcbb16fbc14de466a97d2fbcdee86952",
     "grade": false,
     "grade_id": "comparing_prototypes",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Context model on prototypes:    {}\".format(context_model(prototypes, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on prototypes:  {}\".format(prototype_model(prototypes, all_exemplars, exemplar_categories)))\n",
    "print(\"True prototype categories:      {}\".format(np.array([\"A\", \"B\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Which model is more accurate at predicting the prototypes? Why? (**0.75 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "37ca19498a5826f2a9fbb36721d4bca7",
     "grade": true,
     "grade_id": "comparing_part_b",
     "locked": false,
     "points": 0.75,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Comparing Models: Part C (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Finally, let's take a look at how the models predict the novel stimuli:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d2e8068a4a1fb1099ccd1259e4bb037d",
     "grade": false,
     "grade_id": "comparing_novel_stimuli",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Context model on novel:   {}\".format(context_model(novel_stimuli, all_exemplars, exemplar_categories)))\n",
    "print(\"Prototype model on novel: {}\".format(prototype_model(novel_stimuli, all_exemplars, exemplar_categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">If the true categories of the novel stimuli were $[B, B, B, A]$, which model would be more advantageous in this scenario (remember that category $B$ is the unsafe buttons)? Explain your answer. (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "389ac48071c4e0018c073fcccbaebac1",
     "grade": true,
     "grade_id": "comparing_part_c_1",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">If the true categories of the novel stimuli were $[B, B, A, A]$? Explain your answer. (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "25c963f61b6f0132dcd35156795d9070",
     "grade": true,
     "grade_id": "comparing_part_c_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---\n",
    "## Comparing Models: Part D (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\"> Participants in experiments are better (more accurate and/or faster) at classifying a prototype of previously seen stimuli than classifying new stimuli generated from that prototype: an effect called the **prototype effect**. Would the context / exemplar model be able to account for this effect in people? Why is it that the context / exemplar model can/cannot explain this effect? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "69b1c026d9a11b3ea6cf77b59f1802ab",
     "grade": true,
     "grade_id": "comparing_part_d_1",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\"> Would the prototype model be able to account for this effect in people? Why is it that the prototype model can/cannot explain this effect? (**0.5 points**)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1f067ad41fb858871d7a85e12ee69876",
     "grade": true,
     "grade_id": "comparing_part_d_2",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
